---
title: "GEOG 6960 Causality in Geog. Studies 7"
author: 
  - name: "Simon Brewer"
    email: simon.brewer@ess.utah.edu
    affiliations:
      - name: University of Utah
        address: 260 Central Campus Drive
        city: Salt Lake City
        state: UT
        postal-code: 84112
date: last-modified
format:
  html:
    toc: true
editor: visual
---

```{r}
#| echo: false
set.seed(42)
```

## Introduction

In this lab, we'll look at an alternative way of fitting structural equation models (SEMs) using a piecewise approach. This method was developed by Shipley and coworkers over the past 15 years, and has a number of advantages, mainly including a broader range of data types and structures within the SEM. We will use the following datasets: 

- The Grace and Keeley fire/plant abundance dataset (*keeley.csv*)
- A data set of tree mortality from Shipley (2009): *shipley.csv*

As the name implies, this approach works by *piecing* together individual models, each of which describes one *endogenous* variable in the graph. This contrasts with the covariance-based approach of **lavaan** and **semopy** that try to estimate a single model of the covariance model underlying the system. As a result, each individual model can be built using different assumptions (generalized linear models, non-linear models, etc), and we will explore some of this here. 

Currently, this approach is only available through the R library **piecewiseSEM** developed by Lefcheck (https://doi.org/10.1111/2041-210X.12512). It is possible to carry out a similar in other languages, but some of the tests and visualizations would require additional work. 

## Grace and Keeley Dataset

### Data and libraries

As ever, let's start by loading the libraries we will need:

```{r}
library(tidyverse)
library(correlation)
library(piecewiseSEM)
library(lme4)
library(mgcv)
library(sf)
library(tmap)
```

Now load the dataset:

```{r}
keeley <- read.csv("./data/keeley.csv")
str(keeley)
```

And let's plot the correlation matrix: 

```{r}
cor_res <- correlation(keeley)
x <- cor_sort(as.matrix(cor_res))
plot(visualisation_recipe(x))
```

### Three variable model 1

Before building the full SEM for these data, we'll start with the simple three variable model that includes `age`, `firesev` and `cover`. To build the piecewise model, there are a couple of options: you can build the individual models within the piecewise function (`psem`) or you can build the individual models first, then use `psem` to link them. We'll use this second approach as it is a little easier to check what is going on. 

As a reminder, this is the DAG for the three variable model, as a partially mediated model:

```{r echo = FALSE}
library(ggdag)
grace_dag <- dagify(firesev ~ age,
                    cover ~ age + firesev,
                    coords = list(x = c(age = 1,
                                        firesev = 2,
                                        cover = 3), 
                                  y = c(age = 1,
                                        firesev = 2,
                                        cover = 1)
                    ),
                    exposure = "age",
                    outcome = "cover",
                    labels = c(age = "Stand age", 
                               firesev = "Fire severity", 
                               cover = "Plant cover")
)
ggdag(grace_dag, use_labels = "label", text = FALSE) +
  theme_dag()
```

The two endogenous variables are fire severity (`firesev`) and canopy cover (`cover`), so let's build the two models that describe these according to the DAG using simple OLS linear regression:

```{r}
mod1 <- lm(firesev ~ age, data = keeley)
mod2 <- lm(cover ~ age + firesev, data = keeley)
```

As these are just basic linear models, you can use all the usual functions to check them and get more information. Here is the summary output for them:

```{r}
summary(mod1)
```

```{r}
summary(mod2)
```

Both models explain about 20% of the variance in the outcome, which is not great, but the coefficients and models do show significance. 

Now, we'll build the piecewise SEM. This does not require refitting the models, but instead links them together to allow for testing. 

```{r}
keeley_psem1 <- psem(
  mod1, mod2,
  data = keeley
)
keeley_psem1
```

As you can see, the model object simply contains a list of the component models and a brief overview of the data. To test the overall SEM, we need to use the `summary` function:

```{r}
summary(keeley_psem1)
```

And again, there's a lot of output. Let's go through this from top to bottom:

- `Structural Equation Model`: this first section describes the models that were linked, as well as returning the AIC for the full PSEM model (note that this is the just the sum of the individual AICs)
- `Tests of directed separation`: This section tests any missing paths in the model to see if excluding them is justified or not. As the model we have fit is just identified (or saturated), then there are no missing paths to test
- `Global goodness-of-fit`: Two tests are presented here. The first is an approximation of the Chi-squared test used in covariance models. The second (Fisher's $C$) is based on the d-separation tests
- `Coefficients`: a summary of the model coefficients, including standardized coefficients. This should give the same results as the summaries of the two individual `lm` models above
- `Individual R-squared`: the variance explained for each endogenous variable

In this case, the model is just identified, so the additional work of fitting the SEM cannot provide us with any additional information. 

### Three variable model 2

Now let's drop the path between `age` and `cover`, refit the models and re-run the PSEM. 

```{r}
mod1 <- lm(firesev ~ age, data = keeley)
mod2 <- lm(cover ~ firesev, data = keeley)
keeley_psem2 <- psem(
  mod1, mod2,
  data = keeley
)
```

And now test the model (we'll suppresses the progress bar for the purposes of this document):

```{r}
summary(keeley_psem2, .progressBar = FALSE)
```

Now building the PSEM makes sense - we're able to test whether excluding the `age` to `cover` path makes sense. Both the Chi-squared and Fisher's $C$ test are non-significant, which indicates that there is no support for this path in the data, which in turn confirms that excluding it makes sense. This is also shown in the d-separation tests, which shows a test for this excluded path, and the lack of significance further supports the absence of this path. In fact, as we are only excluding a single path, the d-separation and Fisher's $C$ test are equal. 

**piecewiseSEM** also comes with visualization function. We'll use it here to show the paths for this second model, as well as the unstandardized coefficients. (This is built on top of DiagrammeR, a general network visualization package in R, which can be used to further modify the plot.)

```{r eval=FALSE}
plot(keeley_psem2, show = "unstd")
```

![PSEM model](images/psem2.png)

### Full model

We'll finish this section by building the full Grace and Keeley model. The code below builds the individual models with the `psem` function to minimize the code, but you can try to build these first then link them together:

```{r}
keeley_psem3 <- psem(
  lm(hetero ~ distance, data = keeley),
  lm(abiotic ~ distance, data = keeley),
  lm(age ~ distance, data = keeley),
  lm(firesev ~ age, data = keeley),
  lm(cover ~ firesev, data = keeley),
  lm(rich ~ distance + abiotic + hetero + cover, data = keeley),
  data = keeley
)
summary(keeley_psem3, .progressBar = FALSE)
```

And we'll show the plot with standardized coefficients to easier comparison between the paths:

```{r eval=FALSE}
plot(keeley_psem3, show = "std", ns_dashed = TRUE)
```

![PSEM model](images/psem3.png)

There is, not surprisingly, much more output here. There are more individual models, more paths, and more *missing* paths as shown by the large number of d-separation tests. Note that, unlike the covariance approaches, this function uses the structure of the graph ito intuit the direction of the missing paths (i.e. it tests `firesev ~ distance` not the other way around). 

The two global tests provide slightly different information this time. The Chi-squared test is significant, whereas $C$ is not (although it is close). From the d-sep tests, you should see that one missing path is flagged as significant. Try not to rebuild and test this SEM with the additional path added back in. Check the AIC of the previous model and this one to see whether including this appears to made an overall improvement. 

### Nonlinear models

next, we'll look very quickly at an example of including a non-linear model (a spline-based generalized additive model). We'll make a new version of the second 3-variable model, which includes paths from `age` to `firesev` and `firesev` to `cover`. For this, we'll add a nonlinear relationship for the first of these, based on the following scatterplot which shows a weakening of the link between these variables at higher values of `age`:

```{r}
ggplot(keeley, aes(x = age, y = firesev)) +
  geom_point()
```

To do this, we'll use the `gam()` function from the library **mgcv**. We'll simply replace the first of the two models using this function and the `s()` to indicate using a smoothing spline to model the response of `firesev` to `age`:

```{r message=FALSE}
mod1 <- gam(firesev ~ s(age), data = keeley)
mod2 <- lm(cover ~ firesev, data = keeley)
keeley_psem4 <- psem(
  mod1, mod2,
  data = keeley
)
summary(keeley_psem4, .progressBar = FALSE)
```

A couple of things to note here. This doesn't change the global model fit: these tests are based on the same missing path as the previous model. Second, there is no coefficient listed for the first model: as this is a nonlinear model, there is no single coefficient. If you want to see what this looks like, you can simply plot the individual model response:

```{r}
plot(keeley_psem4[[1]])
```

Let's finish this section by comparing the AIC of these two models to see if including the smoother improves overall model fit (despite the additional complexity):

```{r}
AIC(keeley_psem2, keeley_psem4)
```

## Generalized and mixed effects models

For this example, we'll use a synthetic dataset of tree growth and survival from Shipley's 2009 paper. These data are longitudinal, with repeated observations for each tree. The trees are also grouped by site (there are 20 sites). The model that we will fit follows this graph:

```{r}
shipley_dag <- dagify(DD ~ lat,
                      date ~ DD,
                      growth ~ date,
                      live ~ growth,
                      coords = list(x = c(lat = 1,
                                          DD = 2,
                                          date = 3,
                                          growth = 4,
                                          live = 5), 
                                    y = c(lat = 1,
                                          DD = 2,
                                          date = 3,
                                          growth = 2,
                                          live = 1)
                      ),
                      labels = c(lat = "Latitude",
                                 DD = "Degree Day",
                                 date = "Date",
                                 growth = "Growth",
                                 live = "Live")
)
ggdag(shipley_dag, use_labels = "label", 
      text = FALSE) +
  theme_dag()
```

The DAG represents the following processes (taken from Shipley (2009)): 

> Latitude and year generate the number of degree-days at each site. Degree-days then cause the date of bud burst of a tree species. The date of bud burst causes the amount of diameter growth, and diameter growth determines the survival in the subsequent winter

```{r}
shipley %>%
  mutate(tree = as.factor(tree),
         site = as.factor(site)) %>%
  ggplot(aes(x = year, y = Growth, col = tree)) + 
  geom_line() +
  facet_wrap(~site) +
  theme_bw()  + theme(legend.position = "none")
```

There are two additional complexities with these data. 

First, the outcome we want to model is a binary variable (1 = live in a given year, 0 = dead). The appropriate model for these data is a binomial model with a logit link function. 

The second is that the data are grouped: we have repeated observations by tree (for multiple year) and by site (for multiple trees). To account for this structure, we would need to include random effects for both site and tree. 

We'll use R's **lme4** library to build these models. For the first three paths, we'll assume a linear reponse, so we can use the `lmer()` function. Random effects are included by the following syntax `+ (1 | g)` where `g` is the grouping variable (site or tree here). 

```{r warning=FALSE}
mod1 <- lmer(DD ~ lat + (1 | tree) + (1 | site), data = shipley)
mod2 <- lmer(Date ~ DD + (1 | tree) + (1 | site), data = shipley)
mod3 <- lmer(Growth ~ Date + (1 | tree) + (1 | site), data = shipley)
```

As before, you can check any of the individual models with the `summary()` function or any other standard diagnostics.

```{r}
summary(mod1)
```

For the `Live` variable, we'll need to specify a binomial model using `glmer`, with appropriate `family` arguments

```{r}
mod4 <- glmer(Live ~ Growth + (1 | tree) + (1 | site), 
              family = binomial(link = "logit"), data = shipley)
```

We can now link all of these using `psem` to create the PSEM:

```{r}
shipley_psem1 <- psem(
  mod1, mod2, mod3, mod4,
  data = shipley
)
```


```{r warning=FALSE}
summary(shipley_psem1, .progressBar = FALSE)
```

Some things to note in this output:

- You will like have seen some warnings about singular fits: this suggests that some of the models that include the d-separated variable paths could not be fit well, and may suggest that some data standardization is necessary. 
- With that caveat in mind, none of the missing paths were significant
- Fisher's $C$ supports this, suggesting that the model (and DAG) and well supported by the data
- The Chi-squared test cannot be calculated due to the presence of the binomial model
- The coefficient shown for the binomial model (`~0.348`) is on the logit scale (from the binomial model). To convert this to odds, simply take the anti-log (`exp`), which should give you a value of approximately 1.4, indicating an increasing survival probability with higher growth. 

![PSEM model](images/psem4.png)

## Spatial models

As a last example, we'll look at the use of spatial models within piecewiseSEM. As a reminder, our concern with spatial models is that the errors or residuals will be autocorrelated, which implies that the standard errors and model $p$-values will be biased. Incorporating spatial covariance can then help to accoutn for this. To illustrate, we'll use a data set of (more!) trees taken from a forest plot from the Volzhsko-Kamsky reserve in Russia. This example is lightly modified from Jed Byrnes' SEM workshop (https://jebyrnes.github.io/semclass). Let's start by reading in the data:

```{r}
boreal <- read.csv("./data/boreal.csv")
head(boreal)
```

And let's convert this to a simple feature (spatial) object for plotting:

```{r}
boreal_sf <- st_as_sf(boreal, coords = c("x", "y"))
```

```{r warning=FALSE}
tm_shape(boreal_sf) +
  tm_symbols(col = "NDVI", palette = "Greens")
```


Here's the DAG for these data (it's simplifed from the full dataset). This implies some of the following processes:

- Warmer temperatures increase richness and productivity (NDVI)
- Wetter habitats (more negative `wet`) increase productivity
- Higher richness increases productivity

```{r echo=FALSE}
boreal_dag <- dagify(richness ~ temp,
                     NDVI ~ temp + wet + richness,
                     coords = list(x = c(temp = 1, 
                                         wet = 1, 
                                         richness = 2,
                                         NDVI = 2),
                                   y = c(temp = 2, 
                                         wet = 1, 
                                         richness = 2,
                                         NDVI = 1)))

ggdag(boreal_dag) +
  theme_dag()
```

Let's now fit this model. We'll start with aspatial models for the two endogenous variables (`richness` and `NDVI`)

```{r}
mod1 <- lm(richness ~ temp, data = boreal)
mod2 <- lm(NDVI ~ richness + temp + wet, data = boreal)
boreal_psem1 <- psem(
  mod1, mod2,
  data = boreal
)
```

```{r}
summary(boreal_psem1, .progressBar = FALSE)
```



```{r}
boreal_sf$ols_res <- residuals(boreal_psem1)[,2]
tm_shape(boreal_sf) +
  tm_symbols(col = "ols_res")
```

```{r}
distMat <- as.matrix(dist(
  cbind(boreal$x, boreal$y))
)

distsInv <- 1/distMat
diag(distsInv) <- 0
```

```{r}
library(ape)
Moran.I(boreal_sf$ols_res, distsInv)
```

```{r}
richness_gls <- gls(richness ~ temp,
                    data = boreal)
plot(Variogram(richness_gls, form = ~x + y, 
               robust = TRUE, maxDist = 2000, 
               resType = "pearson"))
```

```{r}
ndvi_gls<- gls(NDVI ~ richness + temp + wet,
               data = boreal)
plot(Variogram(ndvi_gls, form = ~x + y, 
               robust = TRUE, maxDist = 2000, 
               resType = "pearson"))
```

```{r}
#Fit using spatial autocorrelation
spaceCor <- corExp(form =~ x+y, nugget = TRUE)
```

```{r}
richness_gls <- gls(richness ~ temp,
                    correlation = spaceCor,
                    data = boreal)
plot(Variogram(richness_gls, form = ~x + y, 
               robust = TRUE, maxDist = 2000, 
               resType = "normalized"))
```

```{r}
ndvi_gls<- gls(NDVI ~ richness + temp + wet,
               correlation = spaceCor,
               data=boreal)
plot(Variogram(ndvi_gls, form = ~x + y, 
               robust = TRUE, maxDist = 2000, 
               resType = "normalized"))
```

```{r}
boreal_psem2 <- psem(
  richness_gls,
  ndvi_gls,
  data = boreal
)
summary(boreal_psem2)
```

```{r}
plot(boreal_psem2)
```




# Appendix: Data files

## Grace and Keeley dataset *keeley.csv*

| Column header | Variable                 |
|---------------|--------------------------|
| distance      | Distance to coast (m)    |
| elev          | Elevation a.s.l.         |
| abiotic       | Abiotic favorability     |
| age           | Age of stand before fire |
| hetero        | Plot heterogeneity       |
| firesev       | Severity of fire         |
| cover         | Cover of plants          |
| rich          | Plant species richness   |

## Shipley dataset *shipley.csv*

This is a synthetic dataset on tree growth and survival. 

| Column header | Variable                 |
|---------------|--------------------------|
| site      | Site of observation    |
| tree          | Tree ID         |
| lat       | Site latitude     |
| year           | Year of observation |
| Date        | Date of first bud burst       |
| DD       | Cumulative degree days until first bud burst |
| Growth         | Annual increase in stem diameter |
| Survival          | Proportional survival  |
| Live          | Alive (1) or dead (0) |

## Boreal dataset *boreal.csv*

This dataset is taken from Alain Zuur's book "Mixed Effects Models and Extensions in Ecology with R"

| Column header | Variable                 |
|---------------|--------------------------|
| point      | Point ID    |
| x          | Easting        |
| y       | Northing     |
| richness           | Species richness |
| NDVI        | NDVI       |
| temp       | Soil temperature |
| wet         | Moisture index |
