---
title: "GEOG 6960 Causality in Geog. Studies 8"
author: 
  - name: "Simon Brewer"
    email: simon.brewer@ess.utah.edu
    affiliations:
      - name: University of Utah
        address: 260 Central Campus Drive
        city: Salt Lake City
        state: UT
        postal-code: 84112
date: last-modified
format:
  html:
    toc: true
editor: visual
---

```{r}
#| echo: false
set.seed(42)
library(reticulate)
use_condaenv("causal")
```

## Introduction

In this lab, we're going to test methods for causal discovery. We'll use a synthetic example, and a quick test with the Grace and Keeley fire/plant abundance dataset (*keeley.csv*).

## Coding SEMs

Both R and Python have packages that allow you to create SEMs and estimate coefficients based on a dataset.

-   R: **lavaan** and **sem**
-   Python: **semopy** (`pip install semopy`)

First load (or install and load) the relevant packages. We'll need some additional packages to explore the data before model building.

::: {.panel-tabset group="language"}
# R

```{r}
#| output: false
library(tidyverse)
library(GGally)
library(lavaan)
library(lavaanPlot)
```

# Python

```{python}
import numpy as np
import pandas as pd
import seaborn as sns
import semopy
import statsmodels.api as sm
import statsmodels.formula.api as smf
```
:::


## Moderation

We'll start with an example of moderation analysis. In contrast to mediation analysis, moderation assumes that one (or more) of the paths in the model has a coefficient that varies dependent on another variable. In statistical modeling this is referred to as an interaction term, and is pretty easy to incorporate. Having a moderation does present a problem, however, as the causal effect calculated across a path is not a single constant, but depends on the second, moderating variable

### Example data

First, we're going to create a synthetic dataset, that include a moderation effect. This will have 4 variables, which we will create as follows:

-   `s` a randomly distributed exogenous variable representing sleep: $s ~ N(6, 2)$
-   `c` a random variable representing whether an individual is a coffee drinker or not ($[0,1]$)
-   `w` an endogenous variable representing wakefulness: $w = 10 + 4\times s + 5 \times c + N(0, 5)$
-   `t` the outcome variable representing test scores: $t = 50 + 20 \times w + N(0, 100)$

Note that this implies *no* direct effect between `c` and `w`, just the moderation effect on `s -> w`. 

::: {.panel-tabset group="language"}
# R

```{r}
set.seed(42) 
N <- 100 
S <- rnorm(N, 6, 2)
C <- sample(c(0,1), N, replace = TRUE)
W <- 10 + 4 * S + 4 * (S*C) + rnorm(N, 0, 5)
T <- 50 + 20 * W + rnorm(N, 0, 100)
df <- data.frame(S = S, C = as.factor(C), W = W, T = T)
```

# Python

```{python}
np.random.seed(42)
n = 100
S = np.random.normal(6, 2, n)
C = np.random.choice([0,1], n, replace=True)
W = 10 + 4 * S + 5 * (S*C) + np.random.normal(0, 5, n)
T = 50 + 20 * W + np.random.normal(0, 100, n)
# e = -0.4*a + -0.4*d + np.random.normal(0, 0.01, n)

df = pd.DataFrame({'S': S,
                   'C': C,
                   'W': W,
                   'T': T})

```
:::

As usual, we'll do a little exploration of the data before moving on.

::: {.panel-tabset group="language"}
# R

```{r}
ggpairs(df)
```

# Python

```{python}
sns.pairplot(df)
```
:::

### Path analysis

Moderation effects can be estimated directly through path analysis or using a structural equation model (SEM). We'll start here with a path analysis. Note that this requires individual models to be built:

- `w ~ s + s:c` where `s:c` represents the interaction between these terms

::: {.panel-tabset group="language"}
# R

```{r}
mod1 <- lm(W ~ S + S:C, df)
summary(mod1)
```

# Python

```{python}
mod1 = smf.ols(formula='W ~ S + S:C', data=df)
fit1 = mod1.fit()
print(fit1.summary())
```
:::

- `t ~ w` 

::: {.panel-tabset group="language"}
# R

```{r}
mod2 <- lm(T ~ W, df)
summary(mod2)
```

# Python

```{python}
mod2 = smf.ols(formula='T ~ W', data=df)
fit2 = mod2.fit()
print(fit2.summary())
```
:::

With these two models fit, we can estimate the causal effect using the product of the path coefficients. To get the effect for non-coffee drinkers, we ignore the interaction coefficient, giving:

::: {.panel-tabset group="language"}
# R

```{r}
c0 = coef(mod1)["S"] * coef(mod2)["W"]
c0
```

# Python

```{python}
c0 = fit1.params['S'] * fit2.params['W']
print(f'Non-coffee drinkers: {np.round(c0, 4)}')
```
:::

For coffee drinkers, we need to include this. Unlike the path coefficients, we simply add this to the effect of `s -> w`:

::: {.panel-tabset group="language"}
# R

```{r}
c1 = (coef(mod1)["S"] + coef(mod1)["S:C1"]) * coef(mod2)["W"]
c1
```

# Python

```{python}
c1 = (fit1.params['S'] + fit1.params['S:C']) * fit2.params['W']
print(f'Coffee drinkers: {np.round(c1, 4)}')
```
:::

The resulting effect is approximately twice that of non-coffee drinkers. To understand where this comes from, take another look at how the data were created. We used an effect of 4 for the path `s -> w`. The moderation effect was also 4, so effect for coffee drinkers should roughly double. Try re-running this but changing the moderation to a different value (e.g. 2) and see if you get the expected change 

### SEM

Next, we'll fit the same model as a structural equation model. As a reminder, this will not give a different estimate of the effect, but will return standard errors on the moderation effect and the Chi-squared test on overall model fit. 

::: {.panel-tabset group="language"}

# R

In R, we'll fit this with **lavaan**. This does not appear to accept the standard formula syntax for an interaction (`:`), so first we'll calculate this by hand:

```{r}
df = df %>%
  mutate(C = as.numeric(C)-1,
         S_C = S * C)
```

Next, let's create the **lavaan** model specification. The basic formula looks like this:

```
W ~ S + S_C
T ~ W
```

However, it would be good to estimate the standard errors on the moderation term. To do this we use variables within the model call to represent the different path coefficients (`a`, `b`, `c`). We can then recombine these to create new values using the `:=` syntax:

```{r}
mod <-
"
## Structural effects
W ~ a*S + b*S_C
T ~ c*W
## Moderated effects
c0 := a * c
c1 := (a+b) * c
"
```

Now let's fit and show the model:

```{r}
sem_mod <- sem(mod, df, fixed.x = FALSE)
summary(sem_mod)
```

At the end of the output, you should see the two causal effects (non-coffee and coffee drinkers).

```{r eval=FALSE}
lavaanPlot(sem_mod, 
  edge_options = list(color = "grey"),
  coefs = TRUE)
```


# Python

In Python, we'll fit this with **semopy**. This does not appear to accept the standard formula syntax for an interaction (`:`), so first we'll calculate this by hand:

```{python}
df['S_C'] = df['S'] * df['C']
```

Next, let's create the **lavaan** model specification:

```{python}
sem_formula = 'W ~ a*S + b*S_C\nT ~ c*W'
```

Now let's fit and show the model:

```{python}
mod = semopy.Model(sem_formula)
res = mod.fit(df, obj='MLW')
```

```{python}
mod.inspect()
```

```{python}
semopy.calc_stats(mod)[['chi2', 'chi2 p-value']]
```

Note that semopy does not allow for the estimation of the additional values, but we can do this as above, with the path models.

:::

## Latent variable models


## Summary

TBD